{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Give a simple coding example on multiple and multilevel \n",
    "inheritance in python.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Student Name : Apeksh Gupta\n",
      " Student Roll No. : 45\n",
      " Student Class : 12\n",
      "Your Maths score is 80\n",
      "Your English score is 87\n",
      "Your Science score is 91\n"
     ]
    }
   ],
   "source": [
    "class Student:\n",
    "   def __init__(self , Name , Roll_no , Class) :\n",
    "      self.Student_name = Name\n",
    "      self.Student_Roll_no = Roll_no\n",
    "      self.Student_Class = Class\n",
    "\n",
    "   def display(self):\n",
    "      print( f\" Student Name : {self.Student_name}\") \n",
    "      print( f\" Student Roll No. : {self.Student_Roll_no}\") \n",
    "      print( f\" Student Class : {self.Student_Class}\") \n",
    "\n",
    "class Score(Student):\n",
    "   def __init__(self , Name , Roll_no , Class ,  Maths , English , Science  ):\n",
    "      super(). __init__( Name , Roll_no , Class) \n",
    "      self.Maths_score = Maths\n",
    "      self.English_score = English\n",
    "      self.Science_score = Science\n",
    "   \n",
    "   def display(self):\n",
    "      super().display()\n",
    "      print(f\"Your Maths score is {self.Maths_score}\")\n",
    "      print(f\"Your English score is {self.English_score}\")\n",
    "      print(f\"Your Science score is {self.Science_score}\")\n",
    "      \n",
    "a = input(\"Enter Students Name : \")\n",
    "b = input(\"Enter Students Roll_no. : \")\n",
    "c =  input(\"Enter Students Class : \")\n",
    "\n",
    "x = int(input(\"Enter Marks Obtained In Maths : \"))\n",
    "y = int(input(\"Enter Marks Obtained In English : \"))\n",
    "z = int(input(\"Enter Marks Obtained In Science : \"))\n",
    "\n",
    "obj = Score(a , b , c , x , y , z )\n",
    "obj.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Make a confusion matrix on this given above dataset, and count   \n",
    "TP,FP ,FN,TN are in the given example. Donâ€™t need to perform   \n",
    "code, just count manually all the components of confusion matrix.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = {\"Actual\" : [ 0 , 1 , 0 , 1 , 1 ] , \"Prediction\" : [ 0, 1 , 1, 0 , 0] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Prediction\n",
       "0       0           0\n",
       "1       1           1\n",
       "2       0           1\n",
       "3       1           0\n",
       "4       1           0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(dt)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Actual\n",
       "1    3\n",
       "0    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Actual\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction\n",
       "0    3\n",
       "1    2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Prediction\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrics =  confusion_matrix( df[\"Actual\"] , df[\"Prediction\"])\n",
    "matrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TP -> 1 , FP -> 1 , FN -> 2 , TN -> 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Accuracy = (1 + 1)/(1+1+2+1)\n",
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Precision = 1/(1 + 1)\n",
    "Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function of python that takes the confusion matrix output   \n",
    "as an input, and return the precision and recall score.  \n",
    "Actual  prediction   \n",
    "0        0    \n",
    "1        1    \n",
    "0        1    \n",
    "1        0   \n",
    "1        0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1],\n",
       "       [2, 1]], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision = TP / (TP+FP)    \n",
    "RECALL SCORE = TP / (TP+FN)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision : 0.5 \n",
      "Recall Score : 0.3333333333333333 \n"
     ]
    }
   ],
   "source": [
    "def func(x):\n",
    "   matrix = x\n",
    "   print(f\"Precision : { matrix[0][0] / (matrix[0][0] + matrix[0][1])  } \")\n",
    "   print(f\"Recall Score : { matrix[0][0] / (matrix[0][0] + matrix[1][0]) } \")\n",
    "\n",
    "func(x = matrics)  # Confusion matrix is passed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
